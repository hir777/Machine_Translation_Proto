import unicodedata
from tqdm import tqdm
import re
import regex


def are_en(sents):
    res = []
    en = re.compile("""[a-zA-Z   # ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆ
                        0-9      # æ•°å­—
                        \u0020-\u002F\u003A-\u0040\u005B-\u0060\u007B-\u007E   # ASCIIè¨˜å·ã®åŠè§’ç‰ˆ
    ]+""")

    print("Checking if downloaded sentences are truly English sentences or not...")
    for sent in tqdm(sents):
        if en.fullmatch(sent) is None:
            res.append(False)
        else:
            res.append(True)
    return res


def are_ja(sents):
    res = []
    ja = regex.compile("""[\u3041-\u309F   # ã²ã‚‰ãŒãª
                            \u30A1-\u30FF\uFF66-\uFF9F   # ã‚«ã‚¿ã‚«ãƒŠ
                            0-9ï¼-ï¼™   # ã‚¢ãƒ©ãƒ“ã‚¢æ•°å­—
                            \p{Numeric_Type=Numeric}   # æ¼¢æ•°å­—ã€ãƒ­ãƒ¼ãƒæ•°å­—
                            \p{Script_Extensions=Han}    # æ¼¢å­—
                            \u0020-\u002F\u003A-\u0040\u005B-\u0060\u007B-\u007E   # ASCIIæ–‡å­—(è¨˜å·)ã®åŠè§’ç‰ˆ
                            \uFF01-\uFF0F\uFF1A-\uFF20\uFF3B-\uFF40\uFF5B-\uFF65\u3000-\u303F   # ASCIIæ–‡å­—(è¨˜å·)å…¨è§’ç‰ˆã¨æ—¥æœ¬èªã®è¨˜å·ã®åŠè§’ç‰ˆ
    ]+""")

    print("Checking if downloaded sentences are truly Japanese sentences or not...")
    for sent in tqdm(sents):
        if ja.fullmatch(sent) is None:
            res.append(False)
        else:
            res.append(True)
    return res


def cleaning(en_sents, ja_sents):
    brackets = re.compile(r"""\<.*?\>|\{.*?\}|\(.*?\)|\[.*?\]|   # æ‹¬å¼§ï¼ˆåŠè§’ï¼‰
                           [\u3008-\u3011\u3014-\u301B]+.*?[\u3008-\u3011\u3014-\u301B]+   # æ‹¬å¼§ï¼ˆå…¨è§’ï¼‰
    """)
    unwanted = re.compile(r"[*#^]+")
    msc = re.compile(r"\\\\|\t|\\\\t|\r|\\\\r")
    newlines = re.compile(r"\\\n|\n")
    urls = re.compile(
        r"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+")
    email = re.compile(
        r"([A-Za-z0-9]+[.-_])*[A-Za-z0-9]+@[A-Za-z0-9-]+(\.[A-Z|a-z]{2,})+")
    encoding_err = re.compile("0000,0000,0000,\w*?")
    multi_space = re.compile("[ ã€€]{2,}")
    emoji = regex.compile("\p{Emoji_Presentation=Yes}+")

    cleaned_en, cleaned_ja = [], []
    length = min(len(en_sents), len(ja_sents))
    print("\nCleaning English sentences...")

    for en_sent, ja_sent in tqdm(zip(en_sents, ja_sents), total=length):
        en_sent = unicodedata.normalize("NFKC", en_sent).strip()
        ja_sent = unicodedata.normalize("NFKC", ja_sent).strip()

        en_sent = urls.sub('', en_sent)
        ja_sent = urls.sub('', ja_sent)

        en_sent = email.sub('', en_sent)
        ja_sent = email.sub('', ja_sent)

        en_sent = msc.sub('', en_sent)
        ja_sent = msc.sub('', ja_sent)

        en_sent = newlines.sub('', en_sent)
        ja_sent = newlines.sub('', ja_sent)

        en_sent = emoji.sub('', en_sent)
        ja_sent = emoji.sub('', ja_sent)

        en_sent = brackets.sub('', en_sent)
        ja_sent = brackets.sub('', ja_sent)

        en_sent = unwanted.sub('', en_sent)
        ja_sent = unwanted.sub('', ja_sent)

        en_sent = multi_space.sub('', en_sent)
        ja_sent = multi_space.sub('', ja_sent)

        en_sent = encoding_err.sub('', en_sent)
        ja_sent = encoding_err.sub('', ja_sent)

        cleaned_en.append(en_sent.strip())
        cleaned_ja.append(ja_sent.strip())

    print(cleaned_en)
    print(cleaned_ja)
    en_tf_ls = are_en(cleaned_en)
    ja_tf_ls = are_ja(cleaned_ja)

    en_ls, ja_ls = [], []
    for idx, (en_tf, ja_tf) in enumerate(zip(en_tf_ls, ja_tf_ls)):
        if en_tf == True and ja_tf == True:
            en_ls.append(cleaned_en[idx])
            ja_ls.append(cleaned_ja[idx])

    return en_ls, ja_ls


# ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
if __name__ == "__main__":
    en_sents = [
        "the college ğŸ¤©provided courses in science , engineering and art , and also established its own internal degree courses in science and engineering , which were ratified by the university of london .",
        "he won the \t fossati prize . \n https://en.wikipedia.org/wiki/Giampiero_Fossati",
        "he was born in haarlem as the son of aart jansz and became a lawyer .",
        "He said (ç§ã¯æ—¥ç³»ã‚¢ãƒ¡ãƒªã‚«äººäºŒä¸–ã§ã™ã€‚).",
        "I    have a ğŸ’¯(pen). timo.33@gmail.com"
    ]

    ja_sents = [
        "å½“æ™‚ ã® ğŸ˜€ğŸ˜ƒå­¦æ ¡ ã¯ ç§‘å­¦ ã€ å·¥å­¦ ã€ ğŸ¤©èŠ¸è¡“ ã® ã‚³ãƒ¼ã‚¹ ã‚’ é–‹è¬› ã— ã€ ãã‚Œ ã‚‰ ã® ã‚³ãƒ¼ã‚¹ ã¯ ãƒ­ãƒ³ãƒ‰ãƒ³ å¤§å­¦ ã‚ˆã‚Š å­¦ä½ ã® æ‰¿èª ã‚’ å—ã‘ ã¦ ã„ ãŸ ã€‚",
        "^ ãƒ”ã‚¿ãƒª è³ ã‚’ ç²å¾— ã— ãŸ ã€‚http://en.wikipedia.org/wiki/Giampiero_Fossati",
        "er wurde in haarlem als sohn von aart jansz geboren und wurde rechtsanwalt.",
        "å½¼ã¯ã€Œæ—¥ç³»ã‚¢ãƒ¡ãƒªã‚«äººäºŒä¸–ã§ã™ã€‚ï¼IVã€ã¨è¨€ã£ãŸã€‚",
        "ç§ã¯ãƒšãƒ³ã€€ã€€ã‚’æŒã£ã¦ã„ã¾ã™ã€‚*ğŸ’¯"
    ]

    #en_tf_ls = are_en(en_sents)
    #ja_tf_ls = are_ja(ja_sents)

    #en_ls, ja_ls = [], []
    # for idx, (en_tf, ja_tf) in enumerate(zip(en_tf_ls, ja_tf_ls)):
    #    if en_tf == True and ja_tf == True:
    #        en_ls.append(en_sents[idx])
    #        ja_ls.append(ja_sents[idx])

    en_ls, ja_ls = cleaning(en_sents=en_sents, ja_sents=ja_sents)

    print(en_ls)
    print(ja_ls)
